{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#introduction","title":"Introduction","text":"<p> <p>Author: Anvita Kar </p> <p>Advisor: Tyson Lee Swetnam </p>"},{"location":"#about","title":"About","text":"<p>Large Language Models (LLMs) show potential in academic research, but are limited due to poor integration with frameworks that combine Model Context Protocol (MCP) with Artificial Intelligence LLMs. Our study compared research workflows before and after MCP integration. The \"Before MCPs\" condition included scientists conducting experiments, manually entering data, organizing data for external applications\u2019 analysis, and collecting the data for presentation. The \"After MCPs\" condition was streamlined; scientists used applications moving directly from data collection to analysis and then presentation. MCP-enhanced workflows were infinitely more efficient \u2013 suggesting these AI integrated tools could improve research productivity by accessing diverse databases and applications. These findings are crucial for full potential interaction with AI in  research through creating powerfully interconnected work environments.</p> <p>My PI is Dr. Tyson Lee Swetnam, and along with being affiliated with KEYS and BIO5, he is the Research Associate Professor of Geoinformatics at The University of Arizona and the Director of Open Science in the Institute for Computation and Data-enabled Insight. Dr. Swetnam is a prominent researcher in the field of cyberinfrastructure and geospatial sciences. Our lab is focused on successfully establishing an MCP (Model Context Protocol) for researchers to share, import, and sort their data. I specifically am working on the ability to get a vibe coding platform set up on the cloud. We are trying to help groups of researchers access data more efficiently and create an open source Anthropic AI platform where productivity will be the number one goal for all users.</p> <p>For a more in depth view to my work with Dr. Swetnam's lab, click here</p> <p>This website follows the FAIR and CARE data principles and hopes to help further open science. </p>"},{"location":"#main-project","title":"Main Project","text":"<p>My lab\u2019s research investigates how LLMs1 can be enhanced with MCP2 connections to create powerful research tools that hopefully revolutionize academic inquiry and discovery. The work focuses on integrating LLMs1 with PostgreSQL3 databases, and text mining capabilities via Weaviate4 MCP2 connections. In simpler terms, this project is like teaching super-smart computer assistants to connect with different databases and research tools effectively, so they can help scientists find information, discover new patterns, and document their work more effectively than ever before.</p>"},{"location":"#results","title":"Results","text":"<p>The MCP-enhanced workflows demonstrated significant improvements in efficiency as expected. Initial testing suggested these AI integrated tools could improve research productivity through seamless access to diverse databases and applications. Any framework created with this idea anticipates providing researchers with unprecedented analytical capabilities and AI partners. This work represents a crucial step toward realizing the full potential of AI as a research partner in academics. These findings may revolutionize research by creating powerful, interconnected research environments that transform how researchers collaborate with AI.</p>"},{"location":"#daily-logs","title":"Daily Logs","text":"<p>Here is a link to my daily logs throughout the summer of KEYS!</p>"},{"location":"Baseinstallations/","title":"Base installations in a VScode server for smooth sailing code. MCP Installation Guide: File System and Fetch","text":"<p>This guide will walk you through installing and configuring the File System and Fetch MCPs (Model Context Protocols) in VS Code using the Cline extension. These are the 2 basic MCPs all users should have installed in their CyVerse VScode Server, so as to not create more errors while working on any complex project.</p>"},{"location":"Baseinstallations/#step-1-update-system-and-install-dependencies","title":"Step 1: Update System and Install Dependencies","text":"<p>Open VS Code Server and open a bash terminal in VS Code (Terminal \u2192 New Terminal)</p> <p>Update your system:    <pre><code>sudo apt update\n</code></pre> Install Node.js and npm:    <pre><code>sudo apt install nodejs npm\n</code></pre> Wait for about 30 secs as your system finishes all installations.</p>"},{"location":"Baseinstallations/#step-2-install-cline-extension","title":"Step 2: Install Cline Extension","text":"<p> Go to the Extensions panel in VS Code (Ctrl+Shift+X)</p> <p>Search for \"Cline\"</p> <p>Install the Cline extension</p> <p>Enter your API key when prompted</p>"},{"location":"Baseinstallations/#step-3-initial-configuration","title":"Step 3: Initial Configuration","text":"<p>In the taskbar on top of the cline logo, click the icon that looks like 3 books stacked on top of each other</p> <p></p> <p>Then go to Installed and click the Configure MCP Servers button.</p> <p>Replace all the code in the <code>cline_mcp_settings.json</code> with this code from the official MCP server github repository. I edited their code after taking the base code from this README.md.</p> <pre><code>{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-filesystem\",\n        \"/home/vscode\",\n        \"/config\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": [\n        \"read_file\"\n      ]\n    },\n    \"github.com/zcaceres/fetch-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/config/Cline/MCP/fetch-mcp/dist/index.js\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"Baseinstallations/#step-4-create-file-path","title":"Step 4: Create File path","text":"<p>The code that you copied into your <code>cline_mcp_settings.json</code> just now is the completed code for both Filesystem and Fetch to be installed automatically. But since we didn't follow the traditional method of installing both MCPs throught Cline (which takes waaaayy longer), some file paths are missing and have to be manually created.</p> <p>Enter this code into your bash terminal</p> <pre><code>mkdir -p /config/Desktop\n</code></pre>"},{"location":"Baseinstallations/#step-5-check-if-mcps-were-installed-correctly","title":"Step 5: Check if MCPs were installed correctly","text":"<p>To check if you were succesful in taking the shortcut, go to 'Installed' under 'MCP Servers' in cline again. Both Filesystem and Fetch should show    - No error messages    - Green \"ON\" button indicating it's active</p> <p></p>"},{"location":"Baseinstallations/#if-thats-what-you-see-then-congratulations-you-are-ready-to-start-any-project-without-base-errors-good-job","title":"If that's what you see then congratulations, you are ready to start any project without base errors. Good Job!","text":""},{"location":"Baseinstallations/#if-instead-you-see-something-like-this-do-not-panic-you-just-have-to-take-the-long-way-around","title":"If instead you see something like this, do not panic. You just have to take the long way around.","text":""},{"location":"Baseinstallations/#step-3-different-initial-configuration","title":"Step 3: Different Initial Configuration","text":"<p>For this method, you still have to follow the first two steps, but instead of adding the previously mentioned code to your <code>cline_mcp_settings.json</code> you will now add this one. This is a basic version of the code directly from the official MCP server github repository, and will later be edited by Cline.</p> <p><code>{ {   \"mcpServers\": {     \"filesystem\": {       \"command\": \"npx\",       \"args\": [         \"-y\",         \"@modelcontextprotocol/server-filesystem\",         \"/home/vscode\",         \"/config\"       ],       \"disabled\": false,       \"autoApprove\": [         \"read_file\"       ]     }   } }</code></p>"},{"location":"Baseinstallations/#step-4-create-file-path_1","title":"Step 4: Create File path","text":"<p>This code in your <code>cline_mcp_settings.json</code> is the code for only Filesystem's installation since CyVerse VScode pulls its data automatically. Right now only one file path is missing and to account for it we manually add a folder.</p> <p>Enter this code into your bash terminal</p> <p><code>bash    mkdir -p /config/Desktop</code></p>"},{"location":"Baseinstallations/#step-5-checking-for-file-system-mcp","title":"Step 5: Checking for File System MCP","text":"<p>To check if you were succesful in installing Filesystem, go to 'Installed' under 'MCP Servers' in cline again.</p> <p>The Filesystem button should show    - No error messages    - Green \"ON\" button indicating it's active</p>"},{"location":"Baseinstallations/#step-6-install-fetch-mcp","title":"Step 6: Install Fetch MCP","text":"<p>Return to the Marketplace tab in Cline Search for and install Fetch MCP During installation:    - Click Allow for all permission requests    - Ignore any error messages that pop up    - Allow Cline to manage the installation process</p> <p>Just wait for the installation to complete</p>"},{"location":"Baseinstallations/#step-7-final-verification","title":"Step 7: Final Verification","text":"<p>Go to Installed MCP Servers one last time Confirm both MCPs are properly installed:    - File System: Shows green \"ON\" button, no errors    - Fetch: Shows green \"ON\" button, no errors</p>"},{"location":"Baseinstallations/#you-have-again-successfully-installed-and-configured-both-file-system-and-fetch-mcps-your-vs-code-server-is-now-ready-to-work-smoothly-with-these-model-context-protocols","title":"You have again successfully installed and configured both File System and Fetch MCPs! Your VS Code server is now ready to work smoothly with these Model Context Protocols.","text":""},{"location":"Baseinstallations/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Error messages during installation: These are normal and expected - Cline will resolve them automatically</li> <li>Permission prompts: Always click \"Allow\" to ensure proper functionality</li> <li>Installation not showing: Refresh the Installed MCP Servers tab</li> <li>Services not starting: Check that the green \"ON\" button is enabled for both services</li> </ul>"},{"location":"Baseinstallations/#your-development-environment-is-now-enhanced-with-file-system-and-fetch-capabilities-through-the-mcp-protocol","title":"Your development environment is now enhanced with File System and Fetch capabilities through the MCP protocol!","text":""},{"location":"acknowledgments/","title":"Acknowledgments","text":""},{"location":"acknowledgments/#acknowledgments","title":"Acknowledgments","text":"<p>[I am grateful to...]</p> <p>[This material relied upon the work of ...]</p> <p>[My Internship was funded by BIO5 Institute KEYS]</p>"},{"location":"assignment1/","title":"Assignment 1","text":""},{"location":"assignment1/#assignment-1-internship-description","title":"Assignment 1: Internship Description","text":"<p>My PI is Dr. Tyson Lee Swetnam, and along with being affiliated with KEYS and BIO5, he is the Research Associate Professor of Geoinformatics at The University of Arizona and the Director of Open Science in the Institute for Computation and Data-enabled Insight. Dr. Swetnam is a prominent researcher in the field of cyberinfrastructure and geospatial sciences. Our lab is focused on successfully establishing an MCP (Model Context Protocol) for researchers to share, import, and sort their data. I specifically am working on the ability to get a vibe coding platform set up on the cloud. We are trying to help groups of researchers access data more efficiently and create an open source Anthropic AI platform where productivity will be the number one goal for all users. </p> <p>My lab requires 2 logos - Bio5 Logo - Data Science Institute Logo</p>"},{"location":"assignment2/","title":"Assignment 2","text":""},{"location":"assignment2/#assignment-2-introduction-to-your-research","title":"Assignment 2: Introduction to your Research","text":""},{"location":"assignment2/#purpose","title":"Purpose:","text":"<p>My lab\u2019s research investigates how LLMs<sup>1</sup> can be enhanced with MCP<sup>2</sup> connections to create powerful research tools that hopefully revolutionize academic inquiry and discovery. The work focuses on integrating LLMs with PostgreSQL<sup>3</sup> databases, and text mining capabilities via Weaviate<sup>4</sup> MCP connections. In simpler terms, this project is like teaching super-smart computer assistants to connect with different databases and research tools effectively, so they can help scientists find information, discover new patterns, and document their work more effectively than ever before.</p>"},{"location":"assignment2/#prior-research","title":"Prior Research","text":"<p>Limited research exists on the integration of MCPs with LLMs for academic research applications, though foundational work has been established in database-LLM integration and text mining. Amer-Yahia explored the intersection of large language models and database research, raising important questions about how LLMs and database systems can enhance each other in research contexts [3]. Additionally, recent work on DB-GPT has demonstrated the potential for LLMs to revolutionize data management systems by serving as intelligent interfaces between users and databases. Research examining LLM integration into scientific workflows has highlighted both opportunities and challenges in incorporating these technologies into academic research practices [2]. However, research combining MCP protocols, database integration, and collaborative research documentation remain largely unexplored, representing a significant gap that our research aims to address.</p>"},{"location":"assignment2/#need-for-study","title":"Need For Study","text":"<p>This research will significantly advance our understanding of how cutting-edge AI systems can be practically implemented to enhance research productivity. By developing and testing MCP-enhanced LLM workflows, this study expects to demonstrate measurable improvements in research efficiency, pattern recognition in large datasets, and the ability to collaborate during research. The integration of Vibe Code<sup>5</sup> methodologies with traditional research approaches could transform how researchers interact with Artificial Intelligence and generate insights.</p>"},{"location":"assignment2/#problem-statement","title":"Problem Statement:","text":"<p>How can Model Context Protocol integrations with state-of-the-art LLMs be optimized to create comprehensive research workflows that enhance database interaction  and collaborative documentation for researchers?</p>"},{"location":"assignment2/#key-and-definitions","title":"Key and definitions:","text":""},{"location":"assignment2/#references","title":"References","text":"<p>[1] Torkamaan, H., Steinert, S., Pera, M. S., Kudina, O., Freire, S. K., Verma, H., \u2026 Oviedo-Trespalacios, O. (2024). Challenges and future directions for integration of large language models into socio-technical systems. Behaviour &amp; Information Technology, 1\u201320. https://doi.org/10.1080/0144929X.2024.2431068</p> <p>[2] Zhou, X., Sun, Z. &amp; Li, G. DB-GPT: Large Language Model Meets Database. Data Sci. Eng. 9, 102\u2013111 (2024). https://doi.org/10.1007/s41019-023-00235-6</p> <p>[3] Binz M, Alaniz S, Roskies A, Aczel B, Bergstrom CT, Allen C, Schad D, Wulff D, West JD, Zhang Q, Shiffrin RM, Gershman SJ, Popov V, Bender EM, Marelli M, Botvinick MM, Akata Z, Schulz E. How should the advancement of large language models affect the practice of science? (2023) https://www.jmir.org/2023/1/e50638/</p> <p>[4] Ali, M, What Is PostgreSQL? How It Works, Use Cases, and Resources, (2024). https://www.datacamp.com/blog/what-is-postgresql-introduction</p> <ol> <li> <p>\u201cLarge Language Models\u201d - Powerful Artificial Intelligence systems that are trained on vast amounts of text data to understand, generate, and manipulate human language\u00a0\u21a9</p> </li> <li> <p>\u201cModel Context Protocol\u201d - An open standard that helps Artificial Intelligence systems access and interact with external tools like databases and other applications. MCPs help your standard LLM be more helpful and versatile, as they access your applications and automatically change anything that needs to be altered.\u00a0\u21a9</p> </li> <li> <p>\"PostgreSQL\" \u2013 An open-source object-relational database management system (ORDBMS) known for its reliability, data integrity, and extensive feature set [1].\u00a0\u21a9</p> </li> <li> <p>\"Weaviate\" \u2013 Open-source vector database that simply reads all of the files you import and is able to comprehensively interpret the data inside them, answering questions about the data with no difficulty.\u00a0\u21a9</p> </li> <li> <p>\"Vibe Code\" \u2013 The process of using the help of different LLMs to generate and edit code. With the extensive use of MCPs, a vibe coder can also save the edited code to their own applications, watching the change happen in real time.\u00a0\u21a9</p> </li> </ol>"},{"location":"assignment3/","title":"Assignment 3","text":""},{"location":"assignment3/#assignment-3-materials-and-methods","title":"Assignment 3: Materials and Methods","text":"<p>My procedure is to compare traditional research methods against MCP enhanced LLM workflows by having researchers use the server my lab and I created and measure the differences in speed, accuracy, and output quality. Our study involves connecting LLMs to PostgreSQL and Weaviate Databases through Model Context Protocols, then testing how well this integrated system performs on typical research activities like database queries, literature searches, and collaborative documentation \u2013 in comparison to conventional methods. This direct approach was chosen because it could provide clear, measurable evidence of whether AI based technology can actually improve research productivity in real-world scenarios.</p> <p>We use PostgreSQL because it handles complex datasets reliably, which researchers are sure to encounter. And Weaviate was chosen for its ability to search through documents and interact with the user using natural language, rather than just keywords. The MCP connections allow the LLM to access data from the researcher's own system, making a more efficient use of their time. Vibe Coding is the primary way to communicate with the systems, because we do not expect researchers to learn complex database programming languages, instead using normal language for smooth interaction.</p> <pre><code>graph TD\n    %% --- Style Definitions ---\n    %% Node Styles\n    classDef purpleTheme fill:#9370DB,stroke:#8A2BE2,stroke-width:2px,color:#fff\n    classDef pinkTheme fill:#DB7093,stroke:#C71585,stroke-width:2px,color:#fff\n\n    %% Subgraph Container Style (Lavender)\n    style S1 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n    style S2 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n    style S3 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n    style S4 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n\n    %% --- Chart Structure ---\n    %% Subgraphs now have an ID (S1, S2, etc.) and a Title in quotes\n    subgraph S1 [\"Research Input &amp; Core Problem\"]\n        A[\"Problem: How to optimize LLM workflows for research?\"]\n    end\n\n    subgraph S2 [\"Core Engine &amp; Integrations\"]\n        B[LLM-Powered Research Tool]\n        C[\"PostgreSQL Database (Structured Data)\"]\n        D[\"Weaviate (Text Mining / Vector Search)\"]\n\n        B -- \"MCP Connection\" --&gt; C\n        B -- \"MCP Connection\" --&gt; D\n    end\n\n    subgraph S3 [\"Methodologies &amp; Outputs\"]\n        E[Enhanced Database Interaction]\n        F[Pattern Recognition in Large Datasets]\n        G[Collaborative Research Documentation]\n        H[Vibe Code Methodologies]\n    end\n\n    subgraph S4 [\"Ultimate Goal\"]\n        I[Revolutionized Academic Inquiry &amp; Discovery]\n    end\n\n    %% --- Flow Logic ---\n    A --&gt; B\n    C --&gt; E\n    D --&gt; F\n    H --&gt; G\n\n    E --&gt; I\n    F --&gt; I\n    G --&gt; I\n\n    %% --- Apply Node Styles ---\n    class A,E,F,G,H,I pinkTheme\n    class B,C,D purpleTheme</code></pre>"},{"location":"assignment4/","title":"Assignment 4","text":""},{"location":"assignment4/#assignment-4-results","title":"Assignment 4: Results","text":"<p>When I get my finished results, I will add images of it to my research poster. My project will probably end with a finished react app website. I will take screenshots and briefly explain the different parts of my website with arrows and text boxes. Hopefully, we will be done by the end of this week \u2013 07/04/2025.</p> <p>The project I decided to do for my results was a chatbot that is trained on the information in my website. Any viewer would just have to ask it questions to </p>"},{"location":"assignment5/","title":"Assignment 5 Conclusion and Discussion","text":""},{"location":"assignment6/","title":"Assignment 6 Title and Short Abstract","text":""},{"location":"assignment6/#title-here","title":"Title Here","text":""},{"location":"assignment6/#short-abstract-here","title":"Short Abstract Here","text":""},{"location":"basicReactApp/","title":"How to Set Up a React App on the CyVerse VS Code Server","text":""},{"location":"basicReactApp/#step-1-configure-your-vscode-server-with-all-the-basic-installations","title":"Step 1: Configure your VScode server with all the basic installations.","text":"<p>If you haven't already, visit this page about the base installations in VS Code and follow the instructions to prep your workspace. This is to ensure that your app has the correct extensions and MCP servers to install correctly.</p>"},{"location":"basicReactApp/#step-2-create-a-react-app","title":"Step 2: Create a React App","text":"<p>In your bash terminal, type or copy/paste this code. This will create a basic react app by accessing React's official create-react-app github repository, which contains the rules and instructions for your computer. </p> <pre><code>cd /config\nnpx create-react-app (your-app-name)\ncd (your-app-name)\n</code></pre>"},{"location":"basicReactApp/#step-3-clone-its-files","title":"Step 3: Clone its files","text":"<p>In order to work with your newly created react app, you need to be able to edit the code in real time. Go to the 'Explorer' on the left side of your screen, the icon should look like this.</p> <p></p> <p>Then click on open folder and from the dropdown menu, choose the folder that has your react app's name on it. The <code>/config</code> directory should automatically show up in the search bar, your react app's files live inside it.</p>"},{"location":"basicReactApp/#step-4-edit-the-packagejson","title":"Step 4: Edit the 'package.json'","text":"<p>After you clone your react app's files, scroll to find the <code>src</code> folder and open the <code>package.json</code> file.</p> <p></p> <p>In that json file, under \"scripts\" edit the \"start\" line to <code>\"start\": \"PUBLIC_URL=/proxy/3001 react-scripts start\",</code>.</p>"},{"location":"basicReactApp/#step-5-build-for-production-with-correct-path","title":"Step 5: Build for Production with Correct Path","text":"<p>Now, for your app to be hosted on the correct proxy network, we need to make a few changes to the protocol path. Add this code to your bash terminal. <pre><code>PUBLIC_URL=/proxy/3001 npm run build\nnpx serve -s build -l 3001 -n\n</code></pre></p>"},{"location":"basicReactApp/#step-5-access-your-app","title":"Step 5: Access Your App","text":"<p>Your app should be up and functioning, visit a url that looks like https://#your-cyverse-url.cyverse.run/proxy/3001/.</p> <p>If your not sure what your cyverse url is, you can just click on \"Ports\" next to your terminal. Then click on the globe icon that appears when you hover your cursor over the number 3001 to open your app in another browser tab.</p> <p> </p>"},{"location":"basicReactApp/#this-is-what-your-screen-should-look-like-at-the-end","title":"This is what your screen should look like at the end.","text":""},{"location":"basicReactApp/#for-future-development","title":"For Future Development:","text":"<p>Make changes to your React code</p> <p>Run <code>PUBLIC_URL=/proxy/3001 npm run build</code></p> <p>Run <code>npx serve -s build -l 3001 -n</code></p> <p>Refresh your browser</p>"},{"location":"basicReactApp/#key-points","title":"Key Points:","text":"<p>Don't use the development server (npm start) with CyVerse - it doesn't work with the proxy</p> <p>Always build for production with the correct PUBLIC_URL=/proxy/3001</p> <p>Use a simple static server like serve to host the built files</p> <p>The URL structure is always https://your-instance.cyverse.run/proxy/PORT/</p>"},{"location":"basicReactApp/#thats-it-this-workflow-will-work-every-time-with-a-cyverse-vice-vscode-server-good-job","title":"That's it! This workflow will work every time with a CyVerse VICE VScode server, good job!","text":""},{"location":"github/","title":"Github Actions","text":""},{"location":"github/#introduction","title":"Introduction","text":"<p>GitHub Actions allows for the automation of tasks within your software development life cycle. Through GitHub actions users can automatically run their software testing scripts. </p>"},{"location":"github/#key-vocabulary","title":"Key Vocabulary","text":""},{"location":"github/#workflows","title":"Workflows","text":"<p>Workflows can be used to design, test, package, release, or deploy a project on GitHub. A workflow can be added to a repository in GitHub using the file name .github/workflows. Workflows consist of one or more jobs that are scheduled/triggered by an event. </p>"},{"location":"github/#events","title":"Events","text":"<p>Events are the activities that trigger the start of a workflow. Workflows can be triggered using pus or pull requests. </p>"},{"location":"github/#runners","title":"Runners","text":"<p>Runners can be hosted by GitHub or own on your own and is basically considered as a server that has GitHub Actions runner application installed. A runner runs one job at a time and reports the progress to GitHub. </p>"},{"location":"github/#jobs","title":"Jobs","text":"<p>A job is a sequence of instructions that run on the same runner. A workflow containing multiple jobs will perform them in parallel by default. You may also set up a pipeline to conduct jobs in a specific order. </p>"},{"location":"github/#steps","title":"Steps","text":"<p>A step is a single task that can be used to execute commands in a job. An action or a shell command can be used as a step. Each step of a task runs on the same runner, allowing all of the activities in that job to exchange data.</p>"},{"location":"github/#actions","title":"Actions","text":"<p>Actions are commands that are used to join steps to create a job. Actions can be created or found on the GitHub community. </p>"},{"location":"github/#github-education","title":"GitHub Education","text":""},{"location":"github/#steps-to-enroll","title":"Steps to Enroll","text":"<ol> <li>Go to the GitHub Education Site and enter your education status as student</li> <li>From here your school email and dated documentation of your enrollment is required</li> <li>After this is approved you have access to the GitHub education student developer pack! </li> </ol>"},{"location":"github/#whats-included-and-functionality","title":"What's Included and Functionality","text":"<p>As part of the GitHub education student developer pack and GitHub global campus students and faculty are granted access to forums, Campus TV, exclusive events, and free software and subscriptions such as Canva Pro, Microsoft Azure, and VS code. </p> <p>note: the student developer pack doesn't include access to GitHub CodeSpaces </p>"},{"location":"hereswhatitsabout/","title":"Here's what it's about","text":"<p>My lab\u2019s research investigates how LLMs can be enhanced with MCP connections to create powerful research tools that hopefully revolutionize academic inquiry and discovery. The work focuses on integrating LLMs with PostgreSQL databases, and text mining capabilities via Weaviate MCP connections. In simpler terms, this project is like teaching super-smart computer assistants to connect with different databases and research tools effectively, so they can help scientists find information, discover new patterns, and document their work more effectively than ever before.</p> <p>Limited research exists on the integration of MCPs with LLMs for academic research applications, though foundational work has been established in database-LLM integration and text mining. Amer-Yahia et al. (2023) [1] explored the intersection of large language models and database research, raising important questions about how LLMs and database systems can enhance each other in research contexts. Additionally, recent work on DB-GPT has demonstrated the potential for LLMs to revolutionize data management systems by serving as intelligent interfaces between users and databases Zhou, X., Sun, Z. &amp; Li,(2024) [2]. Research examining LLM integration into scientific workflows has highlighted both opportunities and challenges in incorporating these technologies into academic research practices Marcel Binz, Stephan Alaniz, Adina Roskies, Balazs Aczel, Carl T Bergstrom, Colin Allen, Daniel Schad, Dirk Wulff, Jevin D West, Qiong Zhang, Richard M Shiffrin, Samuel J Gershman, Vencislav Popov, Emily M Bender, Marco Marelli, Matthew M Botvinick, Zeynep Akata, Eric Schulz (2025, February 4) [3]. However, research combining MCP protocols, database integration, and collaborative research documentation remain largely unexplored, representing a significant gap that our research aims to address.</p> <p>This research will significantly advance our understanding of how cutting-edge AI systems can be practically implemented to enhance research productivity. By developing and testing MCP-enhanced LLM workflows, this study expects to demonstrate measurable improvements in research efficiency, pattern recognition in large datasets, and the ability to collaborate during research. The integration of Vibe Code methodologies with traditional research approaches could transform how researchers interact with Artificial Intelligence and generate insights.</p> <p>How can Model Context Protocol integrations with state-of-the-art LLMs be optimized to create comprehensive research workflows that enhance database interaction  and collaborative documentation for researchers?</p> <pre><code>graph TD\n    %% --- Style Definitions ---\n    %% Node Styles\n    classDef purpleTheme fill:#9370DB,stroke:#8A2BE2,stroke-width:2px,color:#fff\n    classDef pinkTheme fill:#DB7093,stroke:#C71585,stroke-width:2px,color:#fff\n\n    %% Subgraph Container Style (Lavender)\n    style S1 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n    style S2 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n    style S3 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n    style S4 fill:#E6E6FA,stroke:#B57EDC,stroke-width:2px\n\n    %% --- Chart Structure ---\n    %% Subgraphs now have an ID (S1, S2, etc.) and a Title in quotes\n    subgraph S1 [\"Research Input &amp; Core Problem\"]\n        A[\"Problem: How to optimize LLM workflows for research?\"]\n    end\n\n    subgraph S2 [\"Core Engine &amp; Integrations\"]\n        B[LLM-Powered Research Tool]\n        C[\"PostgreSQL Database (Structured Data)\"]\n        D[\"Weaviate (Text Mining / Vector Search)\"]\n\n        B -- \"MCP Connection\" --&gt; C\n        B -- \"MCP Connection\" --&gt; D\n    end\n\n    subgraph S3 [\"Methodologies &amp; Outputs\"]\n        E[Enhanced Database Interaction]\n        F[Pattern Recognition in Large Datasets]\n        G[Collaborative Research Documentation]\n        H[Vibe Code Methodologies]\n    end\n\n    subgraph S4 [\"Ultimate Goal\"]\n        I[Revolutionized Academic Inquiry &amp; Discovery]\n    end\n\n    %% --- Flow Logic ---\n    A --&gt; B\n    C --&gt; E\n    D --&gt; F\n    H --&gt; G\n\n    E --&gt; I\n    F --&gt; I\n    G --&gt; I\n\n    %% --- Apply Node Styles ---\n    class A,E,F,G,H,I pinkTheme\n    class B,C,D purpleTheme</code></pre>"},{"location":"hereswhatitsabout/#everything-that-happened-from-the-start-to-the-end-in-my-summer-at-keys-2025","title":"Everything that happened from the start to the end in my summer at KEYS 2025","text":"<p>Large Language Models (LLMs) have tremendous potential for academic research, but their impact is limited because of poor connectivity with specialized research tools. Recent work on LLM-database integration has established foundational principles, but frameworks that combine Model Context Protocol (MCP) with Artificial Intelligence LLMs are largely nonexistent.</p> <p>During my time with KEYS \u2013 while working in Dr. Tyson Swetnam\u2019s laboratory \u2013 we set out to find the answer to the question \u201cHow can Model Context Protocol integrations with state-of-the-art LLMs be optimized to create comprehensive research workflows that enhance knowledge discovery, database interaction, and collaborative documentation in academic research environments?\u201d Much more simply, we wanted to see the increase in efficiency that researchers could receive, just by using AI in their work.</p> <p>The study was a comparative analysis examining research workflows before and after MCP integration. The \"Before MCPs\" condition involved traditional research where scientists would conduct experiments, manually enter data into databases, organize data for analysis using external applications, and later collect the analyzed data for presentation. The \"After MCPs\" condition greatly streamlined the process by allowing scientists to access applications that directly moved from data collection to analysis and presentation.</p> <p>The MCP-enhanced workflows demonstrated significant improvements in research efficiency as expected, proving our hypothesis to be correct. Initial testing suggested these AI integrated research tools could dramatically improve research productivity because of seamless access to diverse data sources and applications. Any framework created based on this idea is anticipated to provide researchers with unprecedented analytical capabilities and collaborative AI partners.</p> <p>This work represents a crucial step toward realizing the full potential of AI as a research partner in academic inquiry. The findings may revolutionize research by creating more powerful, interconnected research environments that transform how researchers collaborate with AI systems</p>"},{"location":"hereswhatitsabout/#key-and-definitions","title":"Key and definitions:","text":"<p>LLMs \u2013 \u201cLarge Language Models\u201d aka powerful Artificial Intelligence systems that are trained on vast amounts of text data to understand, generate, and manipulate human language</p> <p>MCP \u2013 \u201cModel Context Protocol\u201d aka an open standard that helps Artificial Intelligence systems access and interact with external tools like databases and other applications. MCPs help your standard LLM be more helpful and versatile, as they access your applications and automatically change anything that needs to be altered. PostgreSQL3 \u2013 An open-source object-relational database management system (ORDBMS) known for its reliability, data integrity, and extensive feature set Ali, M (2024, July 3) [4].</p> <p>Weaviate \u2013 Weaviate is an open-source vector database that simply reads all of the files you import and is able to comprehensively interpret the data inside them, answering questions about the data with no difficulty.</p> <p>Vibe Code \u2013 Vibe Coding is the process of using the help of different LLMs to generate and edit code. With the extensive use of MCPs, a vibe coder can also save the edited code to their own applications, watching the change happen in real time.</p>"},{"location":"hereswhatitsabout/#references","title":"References:","text":"<p>[1] Torkamaan, H., Steinert, S., Pera, M. S., Kudina, O., Freire, S. K., Verma, H., \u2026 Oviedo-Trespalacios, O. (2024). Challenges and future directions for integration of large language models into socio-technical systems. Behaviour &amp; Information Technology, 1\u201320. https://doi.org/10.1080/0144929X.2024.2431068</p> <p>[2] Zhou, X., Sun, Z. &amp; Li, G. DB-GPT: Large Language Model Meets Database. Data Sci. Eng. 9, 102\u2013111 (2024). https://doi.org/10.1007/s41019-023-00235-6</p> <p>[3] Binz M, Alaniz S, Roskies A, Aczel B, Bergstrom CT, Allen C, Schad D, Wulff D, West JD, Zhang Q, Shiffrin RM, Gershman SJ, Popov V, Bender EM, Marelli M, Botvinick MM, Akata Z, Schulz E. How should the advancement of large language models affect the practice of science? Proc Natl Acad Sci U S A. 2025 Feb 4;122(5):e2401227121. doi: 10.1073/pnas.2401227121. Epub 2025 Jan 27. PMID: 39869798; PMCID: PMC11804466.</p> <p>[4] Ali, M, What Is PostgreSQL? How It Works, Use Cases, and Resources, (2024). https://www.datacamp.com/blog/what-is-postgresql-introduction</p>"},{"location":"keysassignments/","title":"KEYS Assignments","text":"<p>Assignment 1</p> <p>Assignment 2</p> <p>Assignment 3</p> <p>Assignment 4</p> <p>Assignment 5</p> <p>Assignment 6</p> <p>Poster</p>"},{"location":"logbook/","title":"Logbook","text":"<p>Date written in YYYY-MM-DD format The Daily Logs are short (5-6 sentence) summaries of my daily activities that include: (1) what was the plan? (2) what actually happend? (3) what could I have done better? (4) how I will approach this differently next time? </p>"},{"location":"logbook/#week-1","title":"Week 1","text":""},{"location":"logbook/#training-week-2025-06-02-to-2025-06-06","title":"[Training Week: 2025-06-02 to 2025-06-06]","text":"<p>Throughout Training Week, we were prepped to meet our labs and given a basic idea of what to expect by the KEYS staff and crew. I learnt a lot about bionformatics, AI and data science, with different professors and presenters.</p>"},{"location":"logbook/#week-2","title":"Week 2","text":""},{"location":"logbook/#day-1-2025-06-09-800-am-to-600-pm","title":"[Day 1: 2025-06-09] 8:00 am to 6:00 pm","text":"<p>Today the first thing I worked on was my KEYS Assignment #1: Internship Description. Then I logged into Cyverse and learnt about my discovery environment. I launched a shell workspace and practiced some basic bash code, to see how it worked and what the outputs looked like. Later I connected with a friend from KEYS who I realised was working in the same lab I was. I helped him learn some of the things I had learnt already and we decided to work together so we could help each other. I installed VScode on my laptop and started exploring its abilities. We both learnt how to connect VScode to our GitHub repositories. I also set up Cline - an opensource coding AI assistant - in VScode, and configured GitHub Copilot, both to help me code in the future. I wasn't sure how to check my MCP extension, but with some help I realised it was already set up. We were told by our PIs, to create a Google AI Studio account so we could access Gemini and create API keys. I created an account but quickly found out that we weren't given permission to generate API keys. Later I was told of an alternative by my PI. Then I read a website about vibe coding, because that is what my lab was going to be focused on for now. I also read another website on prompt engineering, both of which were suggested by my mentor, and finally wrote my log for the day.</p>"},{"location":"logbook/#day-2-2025-06-10-800-am-to-600-pm","title":"[Day 2: 2025-06-10] 8:00 am to 6:00 pm","text":"<p>Started the day visiting the website of the KEYS Webinar speaker for tommorrow, Dr. Vignesh Subbian. Then I was told to install 2 MCP servers in VScode, which actually took most of the day, because of the absolutely innumerable number of errors that came through. Yeah, I spent about 4 hours on getting the 2 MCPs - File System and Fetch - set up. We worked on making Gemini APIs accesible to me and a friend in the same lab, we would later find out that it expired very quickly and was impractical to use. We instead used Verde APIs to do our work. At the end I had to make some manual configurations to the code produced by the AI I was using, Cline, so that I could get File System and Fetch set up. After finally getting the 2 MCPs installed, I took a break from facing the errors and revisited the websites on prompt engineering and vibe coding. They were in depth lessons that I will probably come back to tommorrow as well. About an hour later, I moved on to working with the 2 APIs by following an example excercise in Map-Making 101. This came with its own , albeit more manageble, errors. Halfway through the instructions, the CyVerse Workspace I was working on crashed. I lost all of my data and work that I had spent the last 6 hours working on :( . I yelled a little bit if I'm being honest, but when I started all over again, it was easier and faster since I knew what to do already. I bypassed all the errors and learnt from my mistakes - screenshotting all the edits I made to the code so I could help my teammate get to the same place I was. I encountered my final error when the code turned out to be fine, but as I hosted my Map on GitHub Pages, a 404 error would show up. That's where I stopped for the day and decided to come back to it with more vigor tommorrow.</p>"},{"location":"logbook/#day-3-2025-06-11-800-am-1230-pm-keys-seminar-130-pm-to-530-pm","title":"[Day 3: 2025-06-11] (8:00 am - 12:30 pm KEYS seminar) 1:30 pm to 5:30 pm","text":"<p>First thing in the morning I attended a KEYS science seminar with science literacy lessons and guest speaker Dr. Vignesh Subbian. Then I had my KEYS crew meeting till 1:30 and got started on work after. First I had a meeting with an undergraduate student working in my lab, and he introduced me to an application I was going to use called Weaviate. After the meeting I worked on what I had left unfinished yesterday and I finally got past all the errors, getting my Map-making 101 website to work flawlessly. Then I went back and finished reading the 2 about websites that I have been reading bit by bit for the last 2 days, wrote my logbook, and checked out.</p>"},{"location":"logbook/#day-4-2025-06-12-800-am-to-500-pm","title":"[Day 4: 2025-06-12] 8:00 am to 5:00 pm","text":"<p>Today was a little bit slower than the rest, I worked on my research poster and the assignments due KEYS for most of the time. We had to write about our research and its purpose, working on the nitroduction section of our poster. I had some difficulty figuring out what my project was going to be on, but after some communication with my PI, I had a better idea of where to start. Then I worked on setting up weaviate, which I was newly intoduced to and faced many problems. I realised that I actually didn't have the best idea of what I was doing with the lab, so I requested a meeting with them and that was the end of the day. </p>"},{"location":"logbook/#day-5-2025-06-13-800-am-to-600-pm","title":"[Day 5: 2025-06-13] 8:00 am to 6:00 pm","text":"<p>After realising that I didn't know a lot about what I was doing, I decided to pause the coding for a while and read about the applications I was working with. I read about Visual studio code which was the main application I would be working with and coding in with my lab. I read about the application that my PI had made called the Cyverse. I read quite a few websites about Weaviate, since it seemed to be what I was struggling to get set up, including it's official MCP server page, it's Quickstart page, and a few other websites suggested by my lab mentor. Then I had a meeting with my PI and lab mentor who gave me some more things to do. Then I tested the set up of weaviate on VScode and realised that Weaviate could not be fully functional on a web browser based environment. This pushes my need to instal docker on my loaner laptop from the University of Arizona. However because I donthave admin access, I have to contact IT and have them remotely set it up. That...might take a while.... So I got to work on creating something else that my PI had told me to do. I have to make a new part in my KEYS website where I write down instructions, ideas, or comprehensive material regarding my project, that can help \"teach\" students that use what I make. That's where I stopped today, I might work on it during the weekend, happy Friday!!</p>"},{"location":"logbook/#week-3","title":"Week 3","text":""},{"location":"logbook/#2025-06-16-to-2025-06-20-exception-of-thursday-06-19-for-juneteenth-800-am-to-600-pm","title":"[2025-06-16 to 2025-06-20 (Exception of Thursday 06-19 for Juneteenth] 8:00 am to 6:00 pm","text":"<p>This week went by pretty quick, I didn't do a lot of reproducible work and we had Thursday off because UofA was celebrating Juneteenth. I mostly just read A LOT about the things I would use throughout the summer on websites like . . . https://aws.amazon.com/what-is/prompt-engineering/, https://www.jmir.org/2023/1/e50638/, https://www.ibm.com/think/topics/vibe-coding, https://link.springer.com/article/10.1007/s41019-023-00235-6, https://www.datacamp.com/blog/what-is-postgresql-introduction, https://squidfunk.github.io/mkdocs-material/getting-started/, https://www.researchwithrutgers.com/en/publications/how-should-the-advancement-of-large-language-models-affect-the-pr#, https://www.tandfonline.com/doi/full/10.1080/0144929X.2024.2431068. I also read a lot from my PI's website about Generative AI &amp; Prompt Engineering.</p> <p>On Monday I made mermaid diagrams for my website and decided to use one on my research poster. I used Gemini to create the base code, but there were many errors so I had to learn how to make one myself and fix all those errors. I used the official Mermaid website, and edited 2 mermaid diagrams which continued into Tuesday. I was invited to a github repositpry relating to a future project that i would be working on with my PI (https://github.com/tyson-swetnam/techlaunch-car) and explored that on Tuesday. On Wednesday I worked on setting up a data store MCP looking at a powerpoint presentation from Illyong Choi a student at the University of Arizona about AI Verde MCP Server: Bridging Generative AI with CyVerse Data Resources. With that and working on my KEYS assignments, Friday went by pretty quick.</p>"},{"location":"logbook/#week-4","title":"Week 4","text":""},{"location":"logbook/#day-1-2025-06-23-800-am-to-600-pm","title":"[Day 1: 2025-06-23] 8:00 am to 6:00 pm","text":"<p>Start of the week I checked up on my KEYS assignments and looked at what I needed to do for the week. This week we had to present results on our KEYS poster. Instead, I worked on my website, learning how I could make it more professional. I read the documentation for markdown language in mkdoks from its website, https://squidfunk.github.io/mkdocs-material/reference, and edited my assignments accordingly. After that I looked for images for my research poster. I had to ask for permission to use a picture form Descope's Website. I also used a picture from the powerpoint presentation I followed last week, by Illyong Choi. I edited the text in my introduction making it less text heavy and keeping the Key Terms and definitions in the front. Later, I looked back at what I was working on the previous week. I was trying to think of a way to embedd Weaviate into cyverse, maybe as an mcp that the user would install. But halfway through, I had a meeting with my PI and he said to let that go for now, and that we would work on it later. I moved away from that and worked on getting my local VScode set up. I got most of the way through it but realised that I had to install node.js into my computer so I could use it. I wrote a ticket to UofA IT and that was the end of the day.</p>"},{"location":"logbook/#day-2-2025-06-24-800-am-to-600-pm","title":"[Day 2: 2025-06-24] 8:00 am to 6:00 pm","text":"<p>I started the day on Tuesday by going into a cyverse server and installing Filesystem and Fetch MCPs. It took lesser time than usual because I was already familiar with what to type in and where to edit the code so that the 2 MCPs would install instantly. I was told by my PI to find the installation path for cline in the VScode server through Cyverse, and I had to test a bit to figure that out. I tried opening a new server but Cyverse Discovery Environment kept erroring out. I asked my PI and we realised that there was a faulty server somehwere, and all our requests we being taken there. So we decided to overload that server with requests, so that cycerse would have to put us on a good server. I could only start up to 2 analyses at a time, so my PI was more effective, but eventually it did start working. I worked with it for a little while longer to figure out the installations code for cline, which I eventually found and delivered. I also had to find the configurations for the newly sdded Claude code in VScode servers across cyverse. I got access to a new project with  my PI that was about a react app that he was making. My task is to access and host that react app on a webpage opened through Cyverse VScode, with the use of a proxy.</p>"},{"location":"logbook/#day-3-2025-06-25-800-am-to-1230-pm-keys-seminar-200-pm-to-600-pm","title":"[Day 3: 2025-06-25] (8:00 am to 12:30 pm KEYS Seminar) 2:00 pm to 6:00 pm","text":"<p>Wednesday's are seminar days. We had a KEYS Science seminar from 8 am to 12:30 pm. The presenters were previous KEYS alumini, and they presented their research posters while talking about their time at KEYS in the years before us. It was a very informative session, they were able to shed some light on what to do for research oppurtunities after KEYS and how it helped them progress in their professional lives. After the seminar I had a meeting with one of the main KEYS Staff, Jordan who helped me go over the changes on my poster and reiterate some ideas for what my results would look like. I got to working on the changes they suggested and finished as much as I could.</p>"},{"location":"logbook/#day-4-2025-06-26-800-am-to-500-pm","title":"[Day 4: 2025-06-26] 8:00 am to 5:00 pm","text":"<p>I started warking on hosting the new project \"TechLaunch Car\" in VScode. I cloned the git repository and found out that all the proxy networks were connected to a file called \"vite.config.ts\". I edited that file with the help of cline and used CLaude to understand what some of the code meant. I first noticed a lot of errors regarding which coding model to use. VScode was configured to use either Mamba or Conda, and my server, despite having mamba installed would not pick it up. The error messages would say that neither conda nor mamba were detected. I worked on fixing that for a while and when I finally got it to work another error popped up. The proxy wouldn't connect to the website, specifically the frontend one. The backend proxy seemed to be working fine, but the frontend proxy would put up a blank page or a 504 gateway. I saw a 404 error occasionally, and even a connection error that said \"socket hang up\". After a meeting with my PI, I was told to leave working with the TechLaunh project for now and focus on creating my own react app. </p>"},{"location":"logbook/#day-5-2025-06-27-800-am-to-600-pm","title":"[Day 5: 2025-06-27] 8:00 am to 6:00 pm","text":"<p>Today was slow, I worked on updating my logbook since I was a little behind this week. I tried to work in cyverse and continue fiding the path for my customized MCP server file, but the Cyverse VScode server seemes to be down, I could'nt get anything working. I then worked on my KEYS research poster. I completely changed the arrangemt of almost everything based on the advice of my crew leader and worked on making flowcharts. I also inserted images thinking about how interactive and visually appealing I could make it. I decided to remove the mermaid diagram I previously had in my materials and methods section. </p>"},{"location":"logbook/#week-5","title":"Week 5","text":""},{"location":"logbook/#day-1-2025-07-01-830-am-to-200-pm","title":"[Day 1: 2025-07-01] 8:30 am to 2:00 pm","text":"<p>Today I did my KEYS assignments in the morning, I spent about 2-3 hours on the assignments. Then I moved on to creating a tabluar comparision for my materials and methods section instead of the previous mermaid diagram I had made for my website. I decided - with the help of my KEYS crew leader Ellie Dorland - that the materials and methods would include a before and after in the lives of researchers demonstrating the effect MCP integrated LLM tool can have on their work. The before is researchers doing all of thier work manually, storing their collected data in databases, orgainizing them to meet the standard of whatever analysis application they will use, then accessing the database through the machine, waiting for the machine to complete its evaluation, collecting the analyzed data and presenting it in the form of a research paper, thesis or presentation. In place on the long and winding process, researchers can instead access the tools my lab intends to establish and get their analyzed data in minutes. The AI bases tools can import your data from your computer using MCPs, then organize and analyze that database, even going so far to create a folder in your computer with the output result in proper format. </p>"},{"location":"logbook/#day-2-2025-07-01-800-am-to-600-pm","title":"[Day 2: 2025-07-01] 8:00 am to 6:00 pm","text":"<p>I started the day by reading an article on how google has opened Gemini in Google Classroom for students under the age of 18 by Antonio G. Di Benedetto. Then I used Claude AI to learn how to create my own react app. My PI had suggested that I create a smaller basic React app that I can easily host on a VScode server so that I could find the configurations needed and apply similar ones to host the TechLaunch project later. I launched a Cyverse VScode server and followed the official React App docmentation to start. I didn't have a lot of problems creating it, the process of creating a very basic one is relatively simple. But I faced way too many obstacles in hosting it on a proxy network. I had to take the help of Claude AI to fix the errors that surfaced. I ended up hosting the app on a completely different port than the default 3000, and I adhered the rest of the default code that I got from the documentation to that as well. After a few more hours of iterations, I finally got it to work and that was the end of the day.</p>"},{"location":"logbook/#day-3-2025-07-02-800-am-to-1230-pm-keys-science-seminar-330-pm-to-500-pm","title":"[Day 3: 2025-07-02] (8:00 am to 12:30 pm KEYS Science Seminar) 3:30 pm to 5:00 pm","text":"<p>I didn't have a lot of time left after the science seminar. It ended at 12:30, and I had a lunch break for an hour. Then I started working on my KEYS Slam like we had talked about in the seminar. I went over the components of my poster, and yet again decided to move everything around. I made a different flowchart that progressed horizontally instead of the initial vertical flowchart I had made a few days ago. Then I had a meeting with Jordan (my Science Literacy Instructor) and Ellie (my KEYS Crew Leader), where they gave me feedback about my KEYS Slam, Poster, and Presentation. I was told to add an image correctly along with a few other tips on my KEYS Slam Presentation, which is supposed to be under 2 minutes. That was all the time I had.</p>"},{"location":"logbook/#day-4-2025-07-03-800-am-to-530-pm","title":"[Day 4: 2025-07-03] 8:00 am to 5:30 pm","text":"<p>Today I started with touching up my research poster. I used images from Biorender for most of the illustrations on my \"Materials or Methods\" section. To point out some of the applications and LLMs I used during the summer, I used logos from their official websites. Lastly I finished the \"Discussions/Conclusion\" section, the \"Future Research\" section, and the \"Acknowledgements\" section. At the end, My poster felt vey text heavy, at least towards the bottom so I brought up that qualm with my Crew Leader and moved on. My PI asked me to write down instructions for how I created that basic React App and hosted it in a VScode Server, for other undergraduate students to follow. Working on that for a few hours, I wrote step by step instructions in a page on my website called Basic React app creation. After completing that task I rembered him telling me to write instructions on how I set up my CyVerse VScode server - with the FileSystem and Fetch MCPs, so I did that too. I tried to open another work environment so I could follow along while writing the instructions, but CyVerse seems to be under maintainence since the start of the week. So I had to go off of memory, which was engrained in my head from doing it many times over the course of the summer. I'll still test the instructions when CyVerse is back up. And that was the end of the day, tomorrow is the Fourth of July - a holiday - but I doubt that will stop me from working on my KEYS Slam.</p>"},{"location":"poster/","title":"[Project Name Here]","text":""},{"location":"poster/#description","title":"Description:","text":"<p>[Description of your Project Here]</p>"},{"location":"poster/#introduction","title":"Introduction","text":"<p>[Introductino to your project here]</p>"},{"location":"poster/#methods","title":"Methods","text":"<p>[Methods for your project here]</p>"},{"location":"poster/#results","title":"Results","text":"<p>[Results for your project here]</p>"},{"location":"promptengineering/","title":"Prompt Engineering","text":""},{"location":"promptengineering/#if-you-havent-already-be-sure-to-visit-my-heres-what-its-about-page-it-has-an-extensive-background-on-our-research-with-definitions-to-important-words-that-will-be-used-here","title":"If you haven't already, be sure to visit my Here's what it's about page. It has an extensive background on our research with definitions to important words that will be used here!","text":""},{"location":"promptengineering/#prompt-engineering","title":"Prompt Engineering","text":"<p>\"It's a relatively new field of research that refers to the practice of designing, refining, and implementing prompts or instructions that guide the output of large language models (LLMs) to help in various tasks\" Mesko, B (2023) [1]. Prompt Engineering is the skill of crafting clear, effective instructions for Aritficial Intelligence systems. I have taken a particular liking to using Claude AI and Gemini, but there are many different AIs you can work with, like Chat GPT, Perplexity, and even GitHub Copilot.  Instead of just prompting \"write me a story,\" a good prompt engineer might say \"write a 500-word mystery story set in 1920s Paris, told from the perspective of a detective who speaks in short, clipped sentences.\" The better your prompt, the better results you'll get from the AI.</p>"},{"location":"promptengineering/#heres-a-few-things-i-learnt-by-prompting-everyday","title":"Here's a few things I learnt by Prompting everyday...","text":"<p>Specificity matters enormously. Instead of \"write a report,\" try \"write a 2-page executive summary analyzing PostgreSQL sales data, highlighting the top 3 growth opportunities and 2 main challenges, formatted with bullet points and aimed at daily consumers.\"</p> <p>Context shapes everything. Providing background information, your role, the intended audience, and desired outcome helps the AI understand not just what you want, but why you want it. \"I'm a high school student preparing a lesson on AI for other students\" will get you very different content than \"I'm a Univesity intern researching the use of Artificial INtelligence in Research for a presentation to PHD holders.\"</p> <p>Examples are incredibly powerful. Showing the AI what good output looks like through examples (few-shot prompting) often works better than lengthy descriptions. If you want a specific writing style, provide a sample paragraph.</p> <p>Iterative refinement is normal. Prompt engineering isn't about getting it perfect on the first try - most of the time you start with a decent prompt and refine it based on what you get back. Maybe you need to add constraints, clarify tone, or provide more context.</p> <p>Structure and formatting help. Using clear sections, asking for step-by-step thinking, or requesting specific output formats (like JSON, tables, or numbered lists) can dramatically improve results.</p>"},{"location":"promptengineering/#vibe-coding","title":"Vibe Coding","text":"<p>\"\u201cVibe coding\u201d is introduced by renowned Computer scientist  Andrej Karpathy in February 2025 and emphasized the significance of AI tools in software development. This concept is in line with developments in artificial intelligence (AI) technologies, especially large language models (LLMs) like ChatGPT, Claude and OpenAI's Codex to help developers stay in the zone of creativity and automate coding works\" Harkar, S (2025) [2]</p> <p>A more relaxed, intuitive approach to programming where you focus on getting something that works rather than writing perfect, optimized code. It's about coding based on what information you currently have - maybe you're not sure of the exact syntax, but you write something that captures the general idea and then iterate until it works. I think of it as the programming equivalent of humming a tune you can't quite remember until it sounds right. It's especially popular when prototyping or when you just want to quickly test an idea without getting bogged down in best practices.</p> <p>I've been using a specific coding tool named Cline which I access through a platform called VScode, and write code with it to complete projects.</p> <pre><code>      graph TD\n    %% --- Style Definitions ---\n    classDef redTheme fill:#E56B6F,stroke:#D90429,stroke-width:2px,color:#fff\n    classDef orangeTheme fill:#FFB703,stroke:#FB8500,stroke-width:2px,color:#fff\n    %% ADDED: Style for the invisible spacer nodes\n    classDef spacerTheme fill:transparent,stroke:transparent,stroke-width:0px\n\n    %% --- Chart Structure ---\n    A(When User Has An Idea Or A Goal:)\n\n    subgraph \"Prompt Engineering: The Art of Instruction\"\n        %% ADDED: Invisible spacer node for top padding\n        PE_Spacer( )\n        B([\"Craft a Prompt\"])\n        C1[\"&lt;b&gt;1. Specificity&lt;/b&gt;&lt;br/&gt;&lt;i&gt;e.g., '2-page summary...&lt;br/&gt;highlighting 3 opportunities'&lt;/i&gt;\"]\n        C2[\"&lt;b&gt;2. Context&lt;/b&gt;&lt;br/&gt;&lt;i&gt;e.g., 'I am a high school student...'&lt;/i&gt;\"]\n        C3[\"&lt;b&gt;3. Examples&lt;/b&gt;&lt;br/&gt;&lt;i&gt;(Few-shot prompting)&lt;/i&gt;\"]\n        C4[\"&lt;b&gt;4. Structure&lt;/b&gt;&lt;br/&gt;&lt;i&gt;(Request JSON, tables, etc.)&lt;/i&gt;\"]\n        D{Iterate &amp; Refine}\n        E[\"LLMs&lt;br/&gt;(Claude, Gemini, ChatGPT)&lt;br/&gt;\u00a0\"]\n    end\n\n    subgraph \"Vibe Coding: The Art of Intuition\"\n        %% ADDED: Invisible spacer node for top padding\n        VC_Spacer( )\n        F([\"Write Initial Code\"])\n        G[\"Focus on 'what works'\"]\n        H[\"Prototype quickly\"]\n        I[\"Analogy:&lt;br/&gt;&lt;i&gt;'Humming a tune until it sounds right'&lt;/i&gt;\"]\n        J{Iterate until Functional}\n        K[\"Coding Tools&lt;br/&gt;(VSCode + Cline, Copilot)&lt;br/&gt;\u00a0\"]\n    end\n\n    subgraph \"The Outcome\"\n        L[\"High-Quality AI Output&lt;br/&gt;(Text, Reports, Stories)&lt;br/&gt;\u00a0\"]\n        M[\"Working Code / Functional Prototype&lt;br/&gt;\u00a0\"]\n    end\n\n    %% --- Flow Logic ---\n    %% CHANGED: Point initial flow to the new spacers\n    A ~~~ PE_Spacer &amp; VC_Spacer\n\n    %% ADDED: Connect spacers to first nodes with invisible links\n    PE_Spacer ~~~ B\n    VC_Spacer ~~~ F\n\n    %% The rest of the flow remains the same\n    B --&gt; C1 &amp; C2 &amp; C3 &amp; C4\n    C1 &amp; C2 &amp; C3 &amp; C4 --&gt; D\n    D --&gt; E\n\n    F --&gt; G &amp; H &amp; I\n    G &amp; H &amp; I --&gt; J\n    J --&gt; K\n\n    E --&gt; L\n    K --&gt; M\n\n    %% --- Apply Node Styles ---\n    class B,F,E,K redTheme\n    class A,C1,C2,C3,C4,G,H,I,D,J,L,M orangeTheme\n    %% ADDED: Apply the spacer style to the new nodes\n    class PE_Spacer,VC_Spacer spacerTheme</code></pre>"},{"location":"promptengineering/#references","title":"References:","text":"<p>[1] Mesk\u00f3 B, Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial, J Med Internet Res 2023;25:e50638, URL: https://www.jmir.org/2023/1/e50638, DOI: 10.2196/50638</p> <p>[2] Harkar S, What is Vibe COding, 2025 April 8, https://www.ibm.com/think/topics/vibe-coding</p>"}]}